{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "funcionLambda.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jfpablos/TFM/blob/master/funcionLambda.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "8X7_Wul-D6o1",
        "colab_type": "code",
        "outputId": "c2ce7fc7-ed5b-469b-92cc-f05dc122eba3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1267
        }
      },
      "cell_type": "code",
      "source": [
        "!apt-get update\n",
        "!apt install chromium-chromedriver\n",
        "!pip install selenium\n",
        "!cp /usr/lib/chromium-browser/chromedriver /usr/bin\n",
        "import sys\n",
        "sys.path.insert(0,'/usr/lib/chromium-browser/chromedriver')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:2 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Hit:3 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:9 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ InRelease [3,609 B]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [301 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [410 kB]\n",
            "Get:16 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main Sources [1,636 kB]\n",
            "Get:17 http://security.ubuntu.com/ubuntu bionic-security/multiverse amd64 Packages [4,171 B]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [1,103 kB]\n",
            "Get:19 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran35/ Packages [60.4 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [752 kB]\n",
            "Get:21 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [7,238 B]\n",
            "Get:22 http://ppa.launchpad.net/marutter/c2d4u3.5/ubuntu bionic/main amd64 Packages [786 kB]\n",
            "Fetched 5,331 kB in 4s (1,206 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-410\n",
            "Use 'apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-codecs-ffmpeg-extra\n",
            "Suggested packages:\n",
            "  webaccounts-chromium-extension unity-chromium-extension adobe-flashplugin\n",
            "The following NEW packages will be installed:\n",
            "  chromium-browser chromium-browser-l10n chromium-chromedriver\n",
            "  chromium-codecs-ffmpeg-extra\n",
            "0 upgraded, 4 newly installed, 0 to remove and 37 not upgraded.\n",
            "Need to get 67.9 MB of archives.\n",
            "After this operation, 249 MB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-codecs-ffmpeg-extra amd64 73.0.3683.86-0ubuntu0.18.04.1 [1,111 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser amd64 73.0.3683.86-0ubuntu0.18.04.1 [59.7 MB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-browser-l10n all 73.0.3683.86-0ubuntu0.18.04.1 [2,815 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 chromium-chromedriver amd64 73.0.3683.86-0ubuntu0.18.04.1 [4,355 kB]\n",
            "Fetched 67.9 MB in 3s (23.6 MB/s)\n",
            "Selecting previously unselected package chromium-codecs-ffmpeg-extra.\n",
            "(Reading database ... 131304 files and directories currently installed.)\n",
            "Preparing to unpack .../chromium-codecs-ffmpeg-extra_73.0.3683.86-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-codecs-ffmpeg-extra (73.0.3683.86-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser.\n",
            "Preparing to unpack .../chromium-browser_73.0.3683.86-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-browser (73.0.3683.86-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-browser-l10n.\n",
            "Preparing to unpack .../chromium-browser-l10n_73.0.3683.86-0ubuntu0.18.04.1_all.deb ...\n",
            "Unpacking chromium-browser-l10n (73.0.3683.86-0ubuntu0.18.04.1) ...\n",
            "Selecting previously unselected package chromium-chromedriver.\n",
            "Preparing to unpack .../chromium-chromedriver_73.0.3683.86-0ubuntu0.18.04.1_amd64.deb ...\n",
            "Unpacking chromium-chromedriver (73.0.3683.86-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for mime-support (3.60ubuntu1) ...\n",
            "Setting up chromium-codecs-ffmpeg-extra (73.0.3683.86-0ubuntu0.18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Processing triggers for hicolor-icon-theme (0.17-2) ...\n",
            "Setting up chromium-browser (73.0.3683.86-0ubuntu0.18.04.1) ...\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/x-www-browser (x-www-browser) in auto mode\n",
            "update-alternatives: using /usr/bin/chromium-browser to provide /usr/bin/gnome-www-browser (gnome-www-browser) in auto mode\n",
            "Setting up chromium-chromedriver (73.0.3683.86-0ubuntu0.18.04.1) ...\n",
            "Setting up chromium-browser-l10n (73.0.3683.86-0ubuntu0.18.04.1) ...\n",
            "Collecting selenium\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/d6/4294f0b4bce4de0abf13e17190289f9d0613b0a44e5dd6a7f5ca98459853/selenium-3.141.0-py2.py3-none-any.whl (904kB)\n",
            "\u001b[K    100% |████████████████████████████████| 911kB 18.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3 in /usr/local/lib/python3.6/dist-packages (from selenium) (1.22)\n",
            "Installing collected packages: selenium\n",
            "Successfully installed selenium-3.141.0\n",
            "cp: '/usr/lib/chromium-browser/chromedriver' and '/usr/bin/chromedriver' are the same file\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "e6ab9Yuoji2z",
        "colab_type": "code",
        "outputId": "549356a8-b8b5-4d60-a810-378da8747f89",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install fake-useragent"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting fake-useragent\n",
            "  Downloading https://files.pythonhosted.org/packages/d1/79/af647635d6968e2deb57a208d309f6069d31cb138066d7e821e575112a80/fake-useragent-0.1.11.tar.gz\n",
            "Building wheels for collected packages: fake-useragent\n",
            "  Building wheel for fake-useragent (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/5e/63/09/d1dc15179f175357d3f5c00cbffbac37f9e8690d80545143ff\n",
            "Successfully built fake-useragent\n",
            "Installing collected packages: fake-useragent\n",
            "Successfully installed fake-useragent-0.1.11\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xslH9iXUD3UC",
        "colab_type": "code",
        "outputId": "bd6cfe5a-5c95-447a-8ed7-d26f307ad52d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "cell_type": "code",
      "source": [
        "import csv\n",
        "import requests\n",
        "from datetime import datetime\n",
        "from bs4 import BeautifulSoup\n",
        "from selenium import webdriver\n",
        "from fake_useragent import UserAgent\n",
        "ua = UserAgent()\n",
        "userAgent = ua.random\n",
        "chrome_options = webdriver.ChromeOptions()\n",
        "chrome_options.add_argument('--headless')\n",
        "chrome_options.add_argument('--no-sandbox')\n",
        "chrome_options.add_argument('--disable-dev-shm-usage')\n",
        "chrome_options.add_argument(f'user-agent={userAgent}')\n",
        "wd = webdriver.Chrome('chromedriver',chrome_options=chrome_options)\n",
        "\n",
        "url = {\n",
        "    'google': 'https://www.google.com/search?q=ibex+35&lr=&cr=countryES&hl=es&tbs=ctr:countryES&source=lnms&tbm=nws',\n",
        "    'bing': 'https://www.bing.com/news/search?q=ibex+35&cc=es',\n",
        "    'yahoo': 'https://es.news.search.yahoo.com/search?p=ibex+35',\n",
        "    'duck': 'https://duckduckgo.com/?q=ibex+35&t=h_&iar=news&ia=news&kl=es-es&df=d',\n",
        "    'qwant' : 'https://www.qwant.com/?q=ibex+35&t=news&r=ES',\n",
        "    'ibex': 'http://www.bolsamadrid.es/esp/aspx/Indices/Resumen.aspx'\n",
        "    }\n",
        "def google():\n",
        "  try:\n",
        "    page = requests.get(url['google']).text\n",
        "  except:\n",
        "    print('hay problemas')  \n",
        "  soup = BeautifulSoup(page, \"html.parser\")\n",
        "  text = [t.find('h3').text + '. ' + t.find(class_=\"st\").text for t in soup.find_all(\"div\", {\"class\" :\"g\"})]\n",
        "  text = ' '.join(text)\n",
        "  return text\n",
        "\n",
        "def bing():\n",
        "  page = requests.get(url['bing']).text\n",
        "  soup = BeautifulSoup(page, \"html.parser\")\n",
        "  text = [t.find(class_='title').text + '. ' + t.find(class_='snippet').text for t in soup.find_all('div', class_='t_s')]\n",
        "  text = ' '.join(text)\n",
        "  return text\n",
        "\n",
        "def yahoo():\n",
        "  page = requests.get(url['yahoo']).text\n",
        "  soup = BeautifulSoup(page, \"html.parser\")\n",
        "  text = [p.find('h3').text + '. ' + p.find('p').text for p in soup.find(class_='searchCenterMiddle').find_all('li')]\n",
        "  text = ' '.join(text)\n",
        "    \n",
        "  return text\n",
        "\n",
        "def duck():\n",
        "  wd.get(url['duck'])\n",
        "  text = [t.text for t in wd.find_elements_by_xpath(\"//div[@class='results js-vertical-results']/div/div/h2/a\")]\n",
        "  text = list(filter(None, text))\n",
        "  text = '. '.join(text)\n",
        "  return text\n",
        "\n",
        "def qwant():\n",
        "  wd.get(url['qwant'])\n",
        "  text = [t.text for t in wd.find_elements_by_xpath(\"//div[@class='result-type__news__item']/div[@class='result-type__news__text--container']/a\")]\n",
        "  text = ' '.join(text)\n",
        "  return text"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:14: DeprecationWarning: use options instead of chrome_options\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "nyo77GrNIxmB",
        "colab_type": "code",
        "outputId": "ec09574e-9628-4db8-f3fc-182313a6bfa5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "0HSPO2sZIYsX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import boto3\n",
        "ACCESS_KEY= ''\n",
        "SECRET_KEY = ''\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fEfsF7QjdWkF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s3 = boto3.resource('s3', aws_access_key_id=ACCESS_KEY, aws_secret_access_key=SECRET_KEY)\n",
        "s3.meta.client.download_file('webscraping-buscadores', 'scrapBuscadores.csv', 'scrapBuscadores.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vnRqDpGZef1e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "  with open('scrapBuscadores.csv', 'a') as csv_file:\n",
        "        writer = csv.writer(csv_file)\n",
        "        writer.writerow([datetime.now(), google(), bing(), yahoo(), duck(), qwant()])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "UO-V89RefpCC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "s3.meta.client.upload_file('scrapBuscadores.csv', 'webscraping-buscadores', 'scrapBuscadores.csv', ExtraArgs={'ACL':'public-read'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nsF6JewvRYIf",
        "colab_type": "code",
        "outputId": "9c5744f4-16e9-4bc6-9727-3dddecf03c6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "cell_type": "code",
      "source": [
        "myString = '   '\n",
        "def hayString(xxx):\n",
        "  if xxx.isspace() or not xxx:\n",
        "    print('no hay texto')\n",
        "    hayString('a')\n",
        "  else:\n",
        "    print('seguir')\n",
        "  \n",
        "hayString(myString)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "no hay texto\n",
            "seguir\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
